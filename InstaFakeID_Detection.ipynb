{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awesome786engineer/Machine-Learning-Projects/blob/main/InstaFakeID_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "8qhi90Wg4fXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHr8RphtQIjI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYnxGGQLPAzA"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"nahiar/instagram_bot_detection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHQKMhd1QAIR"
      },
      "outputs": [],
      "source": [
        "df = dataset['train'].to_pandas()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Nr3KvCpw5uN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the DF before applying train test split\n",
        "df_shuffled = df.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
        "\n",
        "splitting_point = int(0.8*len(df))\n",
        "train_df = df_shuffled.iloc[:splitting_point]\n",
        "test_df = df_shuffled.iloc[splitting_point:]"
      ],
      "metadata": {
        "id": "6hikm0KC52ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J03R8lQiVR66"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac = 1,random_state = 42).reset_index(drop = True)\n",
        "test_df = test_df.sample(frac = 1,random_state = 42).reset_index(drop = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0OkO94CSLCE"
      },
      "outputs": [],
      "source": [
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPb_Lae9SS9o"
      },
      "outputs": [],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWj_qGMTYeH4"
      },
      "outputs": [],
      "source": [
        "len(train_df),len(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzvfMk3KU-LX"
      },
      "source": [
        "Here \"nums/length\" and nums/length_full_name\" is ratio of numerical characters in its user name and its full name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZwyLmwINIsi"
      },
      "source": [
        "## MLWorkFLow ##\n",
        "\n",
        "1. Data preprocessing used\n",
        "\n",
        "    -  missing numerical values were replaced by mediian values reducing effect of  outliers\n",
        "    -  missing categorical values(eg profile picture ) were replaced with mode  \n",
        "2. Data transformation\n",
        "\n",
        "    - apply one hot encoding for features \"profile pic\",\"private\",\"external URL\", presence = 1, absence = 0\n",
        "\n",
        "3. Outlier Detection and Removal\n",
        "    \n",
        "    - use interquartile range or z- score method to detect and remove outlier that might skew the model performance\n",
        "\n",
        "4. Feature selection\n",
        "\n",
        "    - to avoid multicollinearity using \"CORRELATION MATRIX\"\n",
        "    - lasso (L1) regularization to select importnat features by shrinking the less important features coefficients to zero\n",
        "    - use RECURSIVE FEATURE ELEMINATION to select top performin features by iteratively training and eliminating weaker features\n",
        "\n",
        "5. Normalization\n",
        "\n",
        "    - normalize high performing features\n",
        "\n",
        "6. Model building using\n",
        "    - for now logistic regression only\n",
        "    - later implement 1. KNN ,2. Random Forest,3. SVC(support vector classifier)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMFuko1oHZtx"
      },
      "source": [
        "# OUTLIER DETECTION AND REMOVAL #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wayp72-XvelL"
      },
      "outputs": [],
      "source": [
        "# plot the distribution of all numeric features\n",
        "binary_columns = [\"profile pic\",\"name==username\",\"external URL\",\"private\",\"fake\"]\n",
        "non_binary_columns = [col for col in train_df.columns if col not in binary_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4-Hs1B8W4S2"
      },
      "outputs": [],
      "source": [
        "len(non_binary_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMCWkivUMfdG"
      },
      "outputs": [],
      "source": [
        "non_binary_columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in non_binary_columns[1:]:\n",
        "  sns.histplot(data = train_df,x = col,kde = True)\n",
        "  plt.show"
      ],
      "metadata": {
        "id": "w2MrjR-u9q19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBfyFC5hYIcN"
      },
      "outputs": [],
      "source": [
        "# for i in range(5):\n",
        "#   sns.histplot(data = train_df,x = non_binary_columns[i],kde = True)\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu10ZUP9YWa4"
      },
      "outputs": [],
      "source": [
        "# calculating skewness of all the attributes\n",
        "train_df[non_binary_columns].skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3s5CnxmIb2w"
      },
      "outputs": [],
      "source": [
        "train_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ifItdemBIOK"
      },
      "outputs": [],
      "source": [
        "selected_columns = ['profile pic','nums/length username','fullname words','description length','external URL']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjYlANv8E9jg"
      },
      "source": [
        "# Applying IQR range for Outlier Detection #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhaDriaJE4u-"
      },
      "outputs": [],
      "source": [
        "# making box plot for all the non_binary columns\n",
        "# for col in non_binary_columns:\n",
        "#   train_df.boxplot(column = col)\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnhAaWKHkPt"
      },
      "source": [
        "## capping the outliers #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBFpUrJXHql0"
      },
      "outputs": [],
      "source": [
        "new_train_df = train_df.copy()\n",
        "new_test_df = test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw0TIbHuIgV7"
      },
      "outputs": [],
      "source": [
        "def filter_iqr(original_df,col,new_df,train = True):\n",
        "  Q1 = original_df[col].quantile(0.25)\n",
        "  Q3 = original_df[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower_limit = Q1 - 1.5 * IQR\n",
        "  upper_limit = Q3 + 1.5 * IQR\n",
        "  if train:\n",
        "    new_df[col] = original_df[col].clip(lower = lower_limit ,upper = upper_limit)\n",
        "  else:\n",
        "    new_df[col] = test_df[col].clip(lower = lower_limit ,upper = upper_limit)\n",
        "  return (lower_limit,upper_limit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2ibq5dIIhWd"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "quartile_limits = defaultdict(tuple)\n",
        "for col in non_binary_columns:\n",
        "  quartile_limits[col] = filter_iqr(train_df,col,new_train_df)\n",
        "  filter_iqr(train_df,col,new_test_df,train = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj6h_6MUUcoa"
      },
      "outputs": [],
      "source": [
        "for col in selected_columns:\n",
        "  print(col + \" : \" + str(quartile_limits[col]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWr-J9ryH9EQ"
      },
      "outputs": [],
      "source": [
        "new_train_df[non_binary_columns].skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R-KhzemNL-f"
      },
      "outputs": [],
      "source": [
        "new_test_df[non_binary_columns].skew()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5udBPufTSzp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWSIXcyzKFqf"
      },
      "source": [
        "# Applying Logistic regression on IQR filtered data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm_8KMn8KD5W"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "X_train = new_train_df.drop('fake',axis = 1)\n",
        "y_train = new_train_df['fake']\n",
        "X_test = new_test_df.drop('fake',axis = 1)\n",
        "y_test = new_test_df['fake']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwu5oxeUU7Wm"
      },
      "source": [
        "# Logistic regression without sklearn #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLdOS6L33LBR"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost_vectorized(X, w, b, y):\n",
        "  m = X.shape[0]\n",
        "  z = X @ w + b  # (m,n) @ (n,) -> (m,). Vectorized dot product for all examples!\n",
        "  f_wb = sigmoid(z) # (m,) vector of all predictions\n",
        "\n",
        "  # Element-wise operations on the entire vectors\n",
        "  cost = -y * np.log(f_wb) - (1 - y) * np.log(1 - f_wb)\n",
        "  total_cost = np.sum(cost) / m\n",
        "\n",
        "  return total_cost\n"
      ],
      "metadata": {
        "id": "muyv_PeEibPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_functions_vectorized(X, w, b, y):\n",
        "  m, n = X.shape\n",
        "  z = X @ w + b      # (m,) vector of z for all examples\n",
        "  f_wb = sigmoid(z)  # (m,) vector of all predictions\n",
        "\n",
        "  error = f_wb - y   # (m,) vector of all errors\n",
        "\n",
        "  # (m,) * (m, n) is not what we want. We need (n,) result.\n",
        "  # So we do (n, m) @ (m,) -> (n,)\n",
        "  dj_dw = (X.T @ error) / m # transpose of X(m,n) is X.T(n,m)\n",
        "  dj_db = np.sum(error) / m\n",
        "\n",
        "  return dj_dw, dj_db"
      ],
      "metadata": {
        "id": "PEMvlrEdjO2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vectorized(X, y, alpha, num_iters):\n",
        "  cost_history =[]\n",
        "  w = np.zeros(X.shape[1])\n",
        "  b = 0\n",
        "  for i in range(num_iters):\n",
        "    dj_dw, dj_db = gradient_functions_vectorized(X, w, b, y)\n",
        "    w = w - alpha * dj_dw\n",
        "    b = b - alpha * dj_db\n",
        "\n",
        "    if i % 1000 == 0: # Check cost less frequently to save time\n",
        "        cost = compute_cost_vectorized(X, w, b, y)\n",
        "        cost_history.append(cost)\n",
        "        print(f\"Iteration {i:5d}: Cost {cost:0.4f}\")\n",
        "\n",
        "  return w, b, cost_history\n"
      ],
      "metadata": {
        "id": "rHI7GIp2jU_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_vectorized(X, w, b):\n",
        "  z = X @ w + b\n",
        "  f_wb = sigmoid(z)\n",
        "  p = f_wb >= 0.5 # Creates a boolean array\n",
        "  return p.astype(int)"
      ],
      "metadata": {
        "id": "gOSGeNxUjtkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwe5oe8Dr_aF"
      },
      "outputs": [],
      "source": [
        "#w, b,cost_history = train(X_train[selected_columns].values,y_train,0.01,15000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, b,cost_history = train_vectorized(X_train[selected_columns].values,y_train,0.01,15000)"
      ],
      "metadata": {
        "id": "F3zB5a_Pj7-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict_vectorized(X_test[selected_columns].values,w,b)"
      ],
      "metadata": {
        "id": "-OopTCyckB9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7N4aBP4nJ4G"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNSo79RjC-4C"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tDSrjh7NmwK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUCtTO3X0cKk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(\n",
        "    range(len(cost_history)),  # X-axis: iteration numbers (0 to 9999)\n",
        "    cost_history,              # Y-axis: cost values\n",
        "    color='blue',\n",
        "    linestyle='solid',\n",
        "    linewidth=2\n",
        ")\n",
        "\n",
        "plt.xlabel('Iteration', fontsize=12)\n",
        "plt.ylabel('Cost', fontsize=12)\n",
        "plt.title('Learning Curve (Cost vs. Iterations)', fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXFKKsTg6WtF"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THmQ5-vMLjWo"
      },
      "outputs": [],
      "source": [
        "w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RhTupTyywt7"
      },
      "outputs": [],
      "source": [
        "# testing on real account\n",
        "w = np.array([-2.80260132,  3.60909299, -0.35848741, -0.02805083, -1.33505898])\n",
        "b = 2.659345278516536"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNfEMtKxThLA"
      },
      "outputs": [],
      "source": [
        "for col in selected_columns:\n",
        "  print(col + \" : \" + str(quartile_limits[col]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "98cEHoa024I9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPEfYy5ncFYOhjE73Rgost",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}